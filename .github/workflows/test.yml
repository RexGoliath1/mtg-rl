name: Tests
on: [push, pull_request]

env:
  AWS_REGION: us-east-1
  FORGE_REPO: https://github.com/RexGoliath1/forge.git
  FORGE_BRANCH: feature/rl-daemon-mode

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - name: Install dependencies
        run: uv sync --extra dev

      - name: Lint
        run: uv run python3 -m ruff check .

      - name: Test
        run: uv run python3 -m pytest tests/test_parser.py -v

  docs:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: astral-sh/setup-uv@v5

      - name: Install docs dependencies
        run: uv sync --extra docs

      - name: Build documentation
        run: uv run sphinx-build -b html docs/ docs/_build/html

      - name: Upload docs artifact
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: docs/_build/html/

  # Build-only validation on all pushes and PRs
  docker-build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Dockerfile.collection
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.collection
          push: false
          cache-from: type=gha,scope=collection
          cache-to: type=gha,mode=max,scope=collection

      - name: Build Dockerfile.training (slim base for CI)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.training
          push: false
          build-args: BASE_IMAGE=python:3.11-slim
          cache-from: type=gha,scope=training
          cache-to: type=gha,mode=max,scope=training

  # Smoke test: validate training image works (imports, data loading, training)
  # Catches PYTHONPATH, rglob, and num_actions filtering bugs before ECR push
  docker-smoke-test:
    runs-on: ubuntu-latest
    needs: [docker-build]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build training image (slim base)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.training
          push: false
          load: true
          tags: mtg-training:smoke
          build-args: BASE_IMAGE=python:3.11-slim
          cache-from: type=gha,scope=training

      - name: Generate synthetic test HDF5
        run: |
          # Create synthetic data mimicking collection v1 schema
          # Includes num_actions=0 edge case that caused attempt 6 failure
          mkdir -p /tmp/smoke_data/subdir
          docker run --rm -v /tmp/smoke_data:/out mtg-training:smoke \
            python3 -c "
          import h5py, numpy as np
          np.random.seed(42)
          n = 500
          states = np.random.randn(n, 17).astype(np.float32)
          choices = np.random.randint(0, 10, size=n).astype(np.int32)
          # Mimic collection v1 bug: 60% of num_actions are 0
          num_actions = np.zeros(n, dtype=np.int32)
          num_actions[::3] = np.random.randint(2, 20, size=len(num_actions[::3]))
          decision_types = np.random.randint(0, 5, size=n).astype(np.int32)
          turns = np.random.randint(1, 15, size=n).astype(np.int32)
          # Save in subdirectory (tests rglob vs glob)
          with h5py.File('/out/subdir/test_data.h5', 'w') as f:
              f.create_dataset('states', data=states)
              f.create_dataset('choices', data=choices)
              f.create_dataset('num_actions', data=num_actions)
              f.create_dataset('decision_types', data=decision_types)
              f.create_dataset('turns', data=turns)
          print(f'Created test HDF5: {n} decisions, {(num_actions==0).sum()} with num_actions=0')
          "
          ls -la /tmp/smoke_data/subdir/

      - name: "Smoke 1: Validate Python imports"
        run: |
          docker run --rm mtg-training:smoke \
            python3 -c "
          from src.forge.game_state_encoder import ForgeGameStateEncoder
          from src.training.self_play import SelfPlayTrainer
          from src.models.shared_card_encoder import SharedCardEncoder
          from src.utils.wandb_integration import WandbTracker
          print('All imports successful')
          "

      - name: "Smoke 2: Validate HDF5 data loading (rglob)"
        run: |
          docker run --rm -v /tmp/smoke_data:/data:ro mtg-training:smoke \
            python3 -c "
          from pathlib import Path
          import h5py
          # Must find file in subdirectory via rglob (not glob)
          files = list(Path('/data').rglob('*.h5'))
          assert files, 'No HDF5 found — rglob failed'
          f = h5py.File(files[0], 'r')
          n = len(f['states'])
          assert n > 0, 'Empty HDF5'
          print(f'Loaded {n} decisions from {files[0]}')
          f.close()
          "

      - name: "Smoke 3: Run 1 training epoch"
        run: |
          docker run --rm \
            -v /tmp/smoke_data:/data:ro \
            -e WANDB_MODE=disabled \
            mtg-training:smoke \
            python3 scripts/train_imitation.py \
              --data-dir /data \
              --epochs 1 \
              --batch-size 64 \
              --max-actions 64 \
              --output /tmp/smoke_model.pt \
              --log-dir /tmp/smoke_logs

      - name: Cleanup
        if: always()
        run: rm -rf /tmp/smoke_data

  # End-to-end daemon<->collector integration test (main branch only)
  docker-integration-test:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    needs: [lint-and-test]
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # ── Forge JAR cache ─────────────────────────────────────
      # Saves ~8 min Maven build on 95%+ of runs where Forge hasn't changed
      - name: Get Forge commit SHA
        id: forge-sha
        run: |
          SHA=$(git ls-remote ${{ env.FORGE_REPO }} refs/heads/${{ env.FORGE_BRANCH }} | cut -f1)
          echo "sha=${SHA}" >> $GITHUB_OUTPUT
          echo "Forge commit: ${SHA}"

      - name: Restore Forge JAR cache
        id: jar-cache
        uses: actions/cache@v4
        with:
          path: .forge-jar-cache/
          key: forge-jar-${{ steps.forge-sha.outputs.sha }}

      - name: Prepare JAR cache directory
        run: |
          mkdir -p .forge-jar-cache
          touch .forge-jar-cache/.keep
          if [ -f .forge-jar-cache/forge.jar ]; then
            echo "Cache HIT — forge.jar found ($(stat --format=%s .forge-jar-cache/forge.jar) bytes)"
          else
            echo "Cache MISS — Maven build will run inside Docker"
          fi
          ls -la .forge-jar-cache/

      - name: Build daemon image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.daemon
          push: false
          load: true
          tags: mtg-daemon:ci
          cache-from: type=gha,scope=daemon
          cache-to: type=gha,mode=max,scope=daemon

      - name: Extract Forge JAR for future cache
        if: steps.jar-cache.outputs.cache-hit != 'true'
        run: |
          CONTAINER_ID=$(docker create mtg-daemon:ci)
          docker cp "${CONTAINER_ID}:/forge/forge.jar" .forge-jar-cache/forge.jar
          docker rm "${CONTAINER_ID}"
          echo "Cached forge.jar for future runs ($(stat --format=%s .forge-jar-cache/forge.jar) bytes)"

      - name: Build collection image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.collection
          push: false
          load: true
          tags: mtg-collection:ci
          cache-from: type=gha,scope=collection
          cache-to: type=gha,mode=max,scope=collection

      - name: Create output directory
        run: mkdir -p ${{ github.workspace }}/ci_test_output

      - name: Start daemon and wait for healthy
        run: |
          docker run -d --name mtg-daemon-ci \
            -p 17171:17171 \
            --health-cmd="echo 'STATUS' | nc -w 5 localhost 17171 || exit 1" \
            --health-interval=15s \
            --health-timeout=10s \
            --health-retries=20 \
            --health-start-period=300s \
            mtg-daemon:ci

          echo "Waiting for daemon to become healthy..."
          SECONDS=0
          TIMEOUT=360
          while [ $SECONDS -lt $TIMEOUT ]; do
            STATUS=$(docker inspect --format='{{.State.Health.Status}}' mtg-daemon-ci 2>/dev/null || echo "not_found")
            if [ "$STATUS" = "healthy" ]; then
              echo "Daemon healthy after ${SECONDS}s"
              break
            elif [ "$STATUS" = "unhealthy" ]; then
              echo "Daemon is unhealthy, checking logs..."
              docker logs --tail 50 mtg-daemon-ci
              exit 1
            fi
            echo "  Status: $STATUS (${SECONDS}s elapsed)"
            sleep 10
          done

          if [ $SECONDS -ge $TIMEOUT ]; then
            echo "Daemon failed to become healthy within ${TIMEOUT}s"
            docker logs --tail 100 mtg-daemon-ci
            exit 1
          fi

      - name: List daemon decks (debug)
        run: |
          docker exec mtg-daemon-ci ls /forge/userdata/decks/constructed/ | head -20 || echo "Could not list decks"

      - name: Run collector (5 games, 1 worker)
        run: |
          docker run --name mtg-collection-ci \
            --link mtg-daemon-ci:daemon \
            -v ${{ github.workspace }}/ci_test_output:/app/training_data \
            -e PYTHONUNBUFFERED=1 \
            mtg-collection:ci \
            python -u scripts/collect_ai_training_data.py \
              --games 5 \
              --workers 1 \
              --host daemon \
              --port 17171 \
              --output /app/training_data \
              --timeout 60 \
              --decks boros_aggro.dck red_aggro.dck mono_red_aggro.dck

      - name: Verify HDF5 output
        run: |
          echo "=== Output directory contents ==="
          ls -la ${{ github.workspace }}/ci_test_output/

          # Check that at least one HDF5 file exists
          HDF5_COUNT=$(find ${{ github.workspace }}/ci_test_output -name "*.h5" | wc -l)
          echo "Found ${HDF5_COUNT} HDF5 file(s)"
          if [ "$HDF5_COUNT" -eq 0 ]; then
            echo "ERROR: No HDF5 files produced!"
            exit 1
          fi

          # Check file size > 0
          for f in ${{ github.workspace }}/ci_test_output/*.h5; do
            SIZE=$(stat --format=%s "$f" 2>/dev/null || stat -f%z "$f" 2>/dev/null || echo "0")
            echo "  $f: ${SIZE} bytes"
            if [ "$SIZE" -eq 0 ]; then
              echo "ERROR: Empty HDF5 file: $f"
              exit 1
            fi
          done

          # Check summary JSON exists
          SUMMARY_COUNT=$(find ${{ github.workspace }}/ci_test_output -name "summary_*.json" | wc -l)
          echo "Found ${SUMMARY_COUNT} summary JSON file(s)"

          echo "=== Integration test PASSED ==="

      - name: Validate HDF5 datasets
        if: success()
        run: |
          # Use the collection image (has h5py) to validate HDF5 contents
          docker run --rm \
            -v ${{ github.workspace }}/ci_test_output:/data:ro \
            mtg-collection:ci \
            python -c "
          import h5py, sys, glob
          files = glob.glob('/data/*.h5')
          if not files:
              print('No HDF5 files found')
              sys.exit(1)
          for path in files:
              print(f'Validating {path}...')
              with h5py.File(path, 'r') as f:
                  expected_keys = ['states', 'turns', 'choices', 'num_actions', 'decision_types']
                  for key in expected_keys:
                      assert key in f, f'Missing dataset: {key}'
                      assert len(f[key]) > 0, f'Empty dataset: {key}'
                      print(f'  {key}: shape={f[key].shape}')
                  # Check encoding version
                  version = f.attrs.get('encoding_version', 0)
                  print(f'  encoding_version={version}')
                  # Check game_state_json (v2 feature)
                  if 'game_state_json' in f:
                      print(f'  game_state_json: {len(f[\"game_state_json\"])} entries')
                  print(f'  Total decisions: {len(f[\"states\"])}')
          print('All HDF5 files validated successfully')
          "

      - name: Capture daemon logs
        if: always()
        run: docker logs mtg-daemon-ci > ${{ github.workspace }}/daemon.log 2>&1 || true

      - name: Capture collector logs
        if: always()
        run: docker logs mtg-collection-ci > ${{ github.workspace }}/collector.log 2>&1 || true

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-integration-logs
          path: |
            ${{ github.workspace }}/daemon.log
            ${{ github.workspace }}/collector.log
            ${{ github.workspace }}/ci_test_output/
          retention-days: 7

      - name: Cleanup
        if: always()
        run: |
          docker rm -f mtg-daemon-ci mtg-collection-ci 2>/dev/null || true

  # Build + push to ECR on main branch only
  ecr-push:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    needs: [lint-and-test, docker-build, docker-smoke-test]
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # ── Forge JAR cache ─────────────────────────────────────
      # Same cache as docker-integration-test — shared via actions/cache key
      - name: Get Forge commit SHA
        id: forge-sha
        run: |
          SHA=$(git ls-remote ${{ env.FORGE_REPO }} refs/heads/${{ env.FORGE_BRANCH }} | cut -f1)
          echo "sha=${SHA}" >> $GITHUB_OUTPUT
          echo "Forge commit: ${SHA}"

      - name: Restore Forge JAR cache
        id: jar-cache
        uses: actions/cache@v4
        with:
          path: .forge-jar-cache/
          key: forge-jar-${{ steps.forge-sha.outputs.sha }}

      - name: Prepare JAR cache directory
        run: |
          mkdir -p .forge-jar-cache
          touch .forge-jar-cache/.keep
          if [ -f .forge-jar-cache/forge.jar ]; then
            echo "Cache HIT — forge.jar found ($(stat --format=%s .forge-jar-cache/forge.jar) bytes)"
          else
            echo "Cache MISS — Maven build will run inside Docker"
          fi
          ls -la .forge-jar-cache/

      - name: Build and push collection image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.collection
          push: true
          tags: |
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-collection:latest
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-collection:${{ github.sha }}
          cache-from: type=gha,scope=collection
          cache-to: type=gha,mode=max,scope=collection

      - name: Build and push daemon image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.daemon
          push: true
          tags: |
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-daemon:latest
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-daemon:${{ github.sha }}
          cache-from: type=gha,scope=daemon
          cache-to: type=gha,mode=max,scope=daemon

      - name: Extract Forge JAR for future cache
        if: steps.jar-cache.outputs.cache-hit != 'true'
        run: |
          # Build a local copy to extract the JAR (the push action doesn't load)
          docker build -t mtg-daemon:extract \
            -f infrastructure/docker/Dockerfile.daemon .
          CONTAINER_ID=$(docker create mtg-daemon:extract)
          docker cp "${CONTAINER_ID}:/forge/forge.jar" .forge-jar-cache/forge.jar
          docker rm "${CONTAINER_ID}"
          echo "Cached forge.jar for future runs ($(stat --format=%s .forge-jar-cache/forge.jar) bytes)"

      - name: Build and push training image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: infrastructure/docker/Dockerfile.training
          push: true
          tags: |
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-training:latest
            ${{ steps.ecr-login.outputs.registry }}/mtg-rl-training:${{ github.sha }}
          cache-from: type=gha,scope=training
          cache-to: type=gha,mode=max,scope=training
